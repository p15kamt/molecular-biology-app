"""
Module Î³Î¹Î± Ï„Î·Î½ Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ scRNA-seq

Î‘Ï…Ï„ÏŒ Ï„Î¿ module Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯ÎµÏ‚ Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹ Î³Î¹Î± Ï„Î·Î½
Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ single-cell RNA sequencing, ÏƒÏ…Î¼Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î±Î½Î¿Î¼Î­Î½Î¿Ï…
Ï„Î¿Ï… quality control, filtering, ÎºÎ±Î¹ normalization.


Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±: 2025
"""

import streamlit as st
import pandas as pd
import numpy as np
import scanpy as sc
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io
import tempfile
import os
import sys
from pathlib import Path
import warnings

# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· utils directory ÏƒÏ„Î¿ path
sys.path.append(str(Path(__file__).parent.parent / "utils"))

try:
    from memory_utils import (
        memory_monitor, display_memory_info, 
        optimize_adata_memory, suggest_optimization,
        cleanup_memory
    )
    from advanced_memory import memory_manager
    from robust_error_handler import safe_execute, memory_safe_operation, emergency_cleanup
except ImportError:
    # Fallback functions Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¿ memory_utils
    def memory_monitor(func):
        return func
    def display_memory_info():
        pass
    def optimize_adata_memory(adata):
        return adata
    def suggest_optimization(adata):
        return []
    def cleanup_memory():
        pass
    
    # Fallback Î³Î¹Î± robust error handler
    def safe_execute(func_name="Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±"):
        def decorator(func):
            return func
        return decorator
    
    def memory_safe_operation(operation_name="Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±"):
        class DummyContext:
            def __enter__(self): return self
            def __exit__(self, *args): return False
        return DummyContext()
    
    def emergency_cleanup():
        pass
    
    # Fallback Î³Î¹Î± advanced memory manager
    class FallbackMemoryManager:
        def get_system_memory_info(self):
            return {'total_gb': 8, 'available_gb': 4, 'process_mb': 500}
        def should_use_streaming(self, adata):
            return False
        def optimize_adata_for_memory(self, adata):
            return adata
        def safe_display_data(self, adata, max_cells=100, max_genes=100):
            return pd.DataFrame({"Info": ["Fallback mode"]})
        def progressive_qc_calculation(self, adata):
            return adata
        def cleanup_session_memory(self):
            pass
    
    memory_manager = FallbackMemoryManager()

# Î‘Ï€ÏŒÎºÏÏ…ÏˆÎ· warnings Î³Î¹Î± ÎºÎ±Î¸Î±ÏÏŒÏ„ÎµÏÎ· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
warnings.filterwarnings('ignore')

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· scanpy
sc.settings.verbosity = 3  # Î•Ï€Î¯Ï€ÎµÎ´Î¿ verbosity
sc.settings.set_figure_params(dpi=80, facecolor='white')

class DataPreprocessingPage:
    """ÎšÎ»Î¬ÏƒÎ· Î³Î¹Î± Ï„Î· ÏƒÎµÎ»Î¯Î´Î± Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"""
    
    def __init__(self):
        self.adata = None
        self.original_adata = None
        
    def render(self):
        """ÎšÎµÎ½Ï„ÏÎ¹ÎºÎ® Î¼Î­Î¸Î¿Î´Î¿Ï‚ Î³Î¹Î± Ï„Î·Î½ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î·Ï‚ ÏƒÎµÎ»Î¯Î´Î±Ï‚"""
        
        st.title("ğŸ“Š Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ scRNA-seq")
        st.markdown("### Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÏ„ÎµÎ¯Ï„Îµ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÎ±Ï‚")
        
        # Tabs Î³Î¹Î± Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ· Ï„Î·Ï‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“ Î‘Î½Î­Î²Î±ÏƒÎ¼Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½", 
            "ğŸ” Quality Control", 
            "ğŸ§¹ Filtering & Preprocessing",
            "ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±"
        ])
        
        with tab1:
            self._render_upload_section()
            
        with tab2:
            if self.adata is not None:
                self._render_quality_control()
            else:
                st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï Î±Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï€ÏÏÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÏ„Î¿ tab 'Î‘Î½Î­Î²Î±ÏƒÎ¼Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½'")
                
        with tab3:
            if self.adata is not None:
                self._render_preprocessing_section()
            else:
                st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï Î±Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï€ÏÏÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÏ„Î¿ tab 'Î‘Î½Î­Î²Î±ÏƒÎ¼Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½'")
                
        with tab4:
            if self.adata is not None:
                self._render_results_section()
            else:
                st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï Î±Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï€ÏÏÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÏ„Î¿ tab 'Î‘Î½Î­Î²Î±ÏƒÎ¼Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½'")
    
    def _render_upload_section(self):
        """Î¤Î¼Î®Î¼Î± Î±Î½ÎµÎ²Î¬ÏƒÎ¼Î±Ï„Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½"""
        
        st.markdown("#### ğŸ“¤ Î‘Î½Î­Î²Î±ÏƒÎ¼Î± Î‘ÏÏ‡ÎµÎ¯Î¿Ï… Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
        
        # ÎŸÎ´Î·Î³Î¯ÎµÏ‚ Î³Î¹Î± Ï„Î¿ Î±Î½Î­Î²Î±ÏƒÎ¼Î±
        with st.expander("ğŸ“– Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î± Formats & ÎŸÎ´Î·Î³Î¯ÎµÏ‚"):
            st.markdown("""
            **Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î± formats:**
            - **H5AD**: AnnData objects (Ï€ÏÎ¿Ï„Î¹Î¼ÏÎ¼ÎµÎ½Î¿ Î³Î¹Î± scRNA-seq)
            - **CSV**: Gene expression matrix Î¼Îµ cells ÏƒÏ„Î¹Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚, genes ÏƒÏ„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚
            - **TSV**: Tab-separated values
            - **Excel**: .xlsx files
            
            **Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î· Î´Î¿Î¼Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:**
            - Î“ÏÎ±Î¼Î¼Î­Ï‚: ÎšÏÏ„Ï„Î±ÏÎ± (cells)
            - Î£Ï„Î®Î»ÎµÏ‚: Î“Î¿Î½Î¯Î´Î¹Î± (genes)
            - Î¤Î¹Î¼Î­Ï‚: Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ reads/counts
            
            **Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·:** Î“Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ H5AD format Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ metadata.
            """)
        
        # File uploader Î¼Îµ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î¼ÎµÎ³Î¬Î»Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½
        uploaded_file = st.file_uploader(
            "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½",
            type=['h5ad', 'csv', 'tsv', 'xlsx', 'xls'],
            help="Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î± formats: H5AD, CSV, TSV, Excel. ÎœÎ­Î³Î¹ÏƒÏ„Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚: 1GB"
        )
        
        # Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± Î±ÏÏ‡ÎµÎ¯Î± ÎºÎ±Î¹ memory management
        col1, col2 = st.columns([3, 1])
        
        with col1:
            with st.expander("ğŸ’¡ Tips Î³Î¹Î± ÎœÎµÎ³Î¬Î»Î± Î‘ÏÏ‡ÎµÎ¯Î±"):
                st.markdown("""
                **Î“Î¹Î± Î±ÏÏ‡ÎµÎ¯Î± >100MB ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹:**
                - **H5AD format** Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ· ÎºÎ±Î¹ Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
                - **Chunked processing** Î¸Î± ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±
                - **Memory-efficient operations** Î³Î¹Î± Î¼ÎµÎ¯Ï‰ÏƒÎ· RAM usage
                - **Progressive loading** Î¼Îµ Ï€ÏÏŒÎ¿Î´Î¿ ÏƒÏ„Î·Î½ Î¿Î¸ÏŒÎ½Î·
                
                **Î£Ï…Î¼Î²Î¿Ï…Î»Î­Ï‚:**
                - ÎšÎ»ÎµÎ¯ÏƒÏ„Îµ Î¬Î»Î»ÎµÏ‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Î³Î¹Î± Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ· Î¼Î½Î®Î¼Î·
                - Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Subsample option Î³Î¹Î± Î³ÏÎ®Î³Î¿ÏÎ¿ testing
                - Î ÎµÏÎ¹Î¼Î­Î½ÎµÏ„Îµ 2-5 Î»ÎµÏ€Ï„Î¬ Î³Î¹Î± Ï€Î¿Î»Ï Î¼ÎµÎ³Î¬Î»Î± Î±ÏÏ‡ÎµÎ¯Î±
                """)
        
        with col2:
            st.markdown("#### ğŸ§¹ Memory Control")
            if st.button("ğŸ—‘ï¸ Cleanup Memory", help="ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·"):
                memory_manager.cleanup_session_memory()
                st.experimental_rerun()
            
            # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· memory status
            memory_info = memory_manager.get_system_memory_info()
            st.metric(
                "RAM Usage", 
                f"{memory_info['process_mb']:.0f}MB",
                help="Î¤ÏÎ­Ï‡Î¿Ï…ÏƒÎ± Ï‡ÏÎ®ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ Î±Ï€ÏŒ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®"
            )
        
        if uploaded_file is not None:
            with st.spinner("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½..."):
                success = self._load_data(uploaded_file)
                
                if success:
                    st.success("âœ… Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!")
                    self._display_data_summary()
                else:
                    st.error("âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.")
    
    def _load_data(self, uploaded_file):
        """Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Î´Î¹Î¬Ï†Î¿ÏÎ± formats Î¼Îµ memory optimization"""
        
        try:
            file_extension = uploaded_file.name.split('.')[-1].lower()
            file_size_mb = uploaded_file.size / (1024 * 1024)
            
            # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…
            st.info(f"ğŸ“ ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {file_size_mb:.1f} MB")
            
            # Memory-efficient file writing Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± Î±ÏÏ‡ÎµÎ¯Î±
            with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_extension}') as tmp_file:
                if file_size_mb > 100:  # Î“Î¹Î± Î±ÏÏ‡ÎµÎ¯Î± >100MB
                    st.info("ğŸ”„ ÎœÎµÎ³Î¬Î»Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ - Ï‡ÏÎ®ÏƒÎ· chunked loading...")
                    progress_bar = st.progress(0)
                    
                    # Chunked reading
                    chunk_size = 8192  # 8KB chunks
                    bytes_written = 0
                    
                    uploaded_file.seek(0)  # Reset file position
                    while True:
                        chunk = uploaded_file.read(chunk_size)
                        if not chunk:
                            break
                        tmp_file.write(chunk)
                        bytes_written += len(chunk)
                        
                        # Update progress
                        progress = min(bytes_written / uploaded_file.size, 1.0)
                        progress_bar.progress(progress)
                    
                    progress_bar.empty()
                else:
                    # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ® Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Î³Î¹Î± Î¼Î¹ÎºÏÎ¬ Î±ÏÏ‡ÎµÎ¯Î±
                    tmp_file.write(uploaded_file.read())
                
                tmp_path = tmp_file.name
            
            if file_extension == 'h5ad':
                self.adata = sc.read_h5ad(tmp_path)
                
            elif file_extension in ['csv', 'tsv']:
                separator = ',' if file_extension == 'csv' else '\t'
                df = pd.read_csv(tmp_path, sep=separator, index_col=0)
                
                # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ numeric Î±Ï€ÏŒ categorical columns
                numeric_cols = []
                categorical_cols = []
                
                for col in df.columns:
                    try:
                        # Î”Î¿ÎºÎ¹Î¼Î® Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î®Ï‚ ÏƒÎµ numeric
                        pd.to_numeric(df[col], errors='raise')
                        numeric_cols.append(col)
                    except (ValueError, TypeError):
                        categorical_cols.append(col)
                
                # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± AnnData object
                if len(numeric_cols) > 0:
                    # Î§ÏÎ®ÏƒÎ· Î¼ÏŒÎ½Î¿ Ï„Ï‰Î½ numeric columns Î³Î¹Î± Ï„Î¿ X matrix
                    X_data = df[numeric_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
                    self.adata = sc.AnnData(X_data)
                    
                    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· categorical data ÏƒÏ„Î± obs
                    if len(categorical_cols) > 0:
                        for col in categorical_cols:
                            self.adata.obs[col] = df[col].values
                else:
                    # Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ numeric columns, Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏŒÎ»Ï‰Î½
                    X_data = df.apply(pd.to_numeric, errors='coerce').fillna(0)
                    self.adata = sc.AnnData(X_data)
                
            elif file_extension in ['xlsx', 'xls']:
                df = pd.read_excel(tmp_path, index_col=0)
                
                # Î•Ï†Î±ÏÎ¼Î¿Î³Î® Ï„Î·Ï‚ Î¯Î´Î¹Î±Ï‚ Î»Î¿Î³Î¹ÎºÎ®Ï‚ ÏŒÏ€Ï‰Ï‚ ÏƒÏ„Î± CSV
                numeric_cols = []
                categorical_cols = []
                
                for col in df.columns:
                    try:
                        pd.to_numeric(df[col], errors='raise')
                        numeric_cols.append(col)
                    except (ValueError, TypeError):
                        categorical_cols.append(col)
                
                if len(numeric_cols) > 0:
                    X_data = df[numeric_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
                    self.adata = sc.AnnData(X_data)
                    
                    if len(categorical_cols) > 0:
                        for col in categorical_cols:
                            self.adata.obs[col] = df[col].values
                else:
                    X_data = df.apply(pd.to_numeric, errors='coerce').fillna(0)
                    self.adata = sc.AnnData(X_data)
            
            # Advanced memory optimization
            should_stream = memory_manager.should_use_streaming(self.adata)
            if should_stream:
                st.warning("âš¡ ÎœÎµÎ³Î¬Î»Î¿ dataset - ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· streaming mode")
            
            # Memory optimization
            self.adata = memory_manager.optimize_adata_for_memory(self.adata)
            
            # Î‘Î½Ï„Î¹Î³ÏÎ±Ï†Î® Ï„Ï‰Î½ Î±ÏÏ‡Î¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Î¼ÏŒÎ½Î¿ Î±Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Î¼ÎµÎ³Î¬Î»Î¿)
            estimated_size = memory_manager.get_system_memory_info()['process_mb']
            if estimated_size < 1000:  # <1GB
                self.original_adata = self.adata.copy()
            else:
                st.info("ğŸ’¾ Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· backup copy Î»ÏŒÎ³Ï‰ Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ - Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ reload Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ reset")
                self.original_adata = None
            
            # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î±ÏÏ‡ÎµÎ¯Î¿Ï…
            os.unlink(tmp_path)
            
            # Î’Î±ÏƒÎ¹ÎºÏŒÏ‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
            if self.adata.n_obs == 0 or self.adata.n_vars == 0:
                st.error("Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï†Î±Î¯Î½Î¿Î½Ï„Î±Î¹ ÎºÎµÎ½Î¬ Î® Î­Ï‡Î¿Ï…Î½ Î»Î¬Î¸Î¿Ï‚ format.")
                return False
            
            # Î•Ï€Î¹Î»Î¿Î³Î® subsampling Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± datasets
            if self.adata.n_obs > 10000:  # Î“Î¹Î± >10K ÎºÏÏ„Ï„Î±ÏÎ±
                st.warning(f"âš ï¸ ÎœÎµÎ³Î¬Î»Î¿ dataset: {self.adata.n_obs:,} ÎºÏÏ„Ï„Î±ÏÎ±")
                
                use_subsample = st.checkbox(
                    "ğŸ¯ Î§ÏÎ®ÏƒÎ· Subsample Î³Î¹Î± Î³ÏÎ·Î³Î¿ÏÏŒÏ„ÎµÏÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·",
                    value=True,
                    help="Î£Ï…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹ Î³Î¹Î± Î³ÏÎ®Î³Î¿ÏÎ¿ testing Î¼Îµ Î¼ÎµÎ³Î¬Î»Î± datasets"
                )
                
                if use_subsample:
                    sample_size = st.slider(
                        "Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…Ï„Ï„Î¬ÏÏ‰Î½ Î³Î¹Î± subsample:",
                        min_value=1000,
                        max_value=min(50000, self.adata.n_obs),
                        value=min(5000, self.adata.n_obs),
                        step=1000,
                        help="ÎœÎ¹ÎºÏÏŒÏ„ÎµÏÎ¿ sample = Î³ÏÎ·Î³Î¿ÏÏŒÏ„ÎµÏÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·"
                    )
                    
                    if st.button("âœ‚ï¸ Î•Ï†Î±ÏÎ¼Î¿Î³Î® Subsample"):
                        # Random subsample
                        sc.pp.subsample(self.adata, n_obs=sample_size)
                        st.success(f"âœ… Subsample Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: {self.adata.n_obs:,} ÎºÏÏ„Ï„Î±ÏÎ±")
                        st.experimental_rerun()
                
            return True
            
        except Exception as e:
            st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·: {str(e)}")
            return False
    
    def _display_data_summary(self):
        """Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÏƒÏÎ½Î¿ÏˆÎ·Ï‚ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"""
        
        st.markdown("#### ğŸ“‹ Î£ÏÎ½Î¿ÏˆÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎšÏ…Ï„Ï„Î¬ÏÏ‰Î½", f"{self.adata.n_obs:,}")
        with col2:
            st.metric("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î“Î¿Î½Î¹Î´Î¯Ï‰Î½", f"{self.adata.n_vars:,}")
        with col3:
            try:
                # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ…Î½Î¿Î»Î¹ÎºÏÎ½ counts Î¼Îµ Î±ÏƒÏ†Î±Î»Î® Ï„ÏÏŒÏ€Î¿
                total_sum = self.adata.X.sum()
                if hasattr(total_sum, 'item'):  # Î“Î¹Î± numpy arrays/matrices
                    total_counts = int(total_sum.item())
                else:
                    total_counts = int(total_sum)
                display_counts = f"{total_counts:,}"
            except (TypeError, ValueError):
                display_counts = "N/A"
            st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Counts", display_counts)
        with col4:
            try:
                # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ sparsity Î¼Îµ Î±ÏƒÏ†Î±Î»Î® Ï„ÏÏŒÏ€Î¿
                non_zero_count = (self.adata.X > 0).sum()
                if hasattr(non_zero_count, 'item'):
                    non_zero_count = non_zero_count.item()
                total_elements = self.adata.n_obs * self.adata.n_vars
                sparsity = 1 - (non_zero_count / total_elements)
                display_sparsity = f"{sparsity:.1%}"
            except (TypeError, ValueError, ZeroDivisionError):
                display_sparsity = "N/A"
            st.metric("Sparsity", display_sparsity)
        
        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· sample Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        st.markdown("#### ğŸ‘€ Preview Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
        
        # Memory-safe ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î¼Îµ advanced memory manager
        sample_data = memory_manager.safe_display_data(
            self.adata, 
            max_cells=10, 
            max_genes=10
        )
        
        st.dataframe(sample_data, use_container_width=True)
        
        # Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ metadata
        if len(self.adata.obs.columns) > 0:
            st.markdown("#### ğŸ·ï¸ Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Metadata (Observations)")
            st.write(list(self.adata.obs.columns))
            
        if len(self.adata.var.columns) > 0:
            st.markdown("#### ğŸ§¬ Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Metadata (Variables/Genes)")
            st.write(list(self.adata.var.columns))
    
    def _render_quality_control(self):
        """Î¤Î¼Î®Î¼Î± quality control"""
        
        st.markdown("#### ğŸ” Quality Control Metrics")
        
        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ QC metrics
        with st.spinner("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ QC metrics..."):
            self._calculate_qc_metrics()
        
        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· histograms
        self._plot_qc_histograms()
        
        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· scatter plots
        self._plot_qc_scatter()
        
        # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
        self._display_qc_statistics()
    
    def _calculate_qc_metrics(self):
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ quality control metrics Î¼Îµ memory protection"""
        
        import numpy as np
        
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Ï„ÏÏ€Î¿Ï… dataset
        if self.adata.n_obs < 1000 and self.adata.n_vars < 100:
            st.warning("ğŸ” ÎœÎ¹ÎºÏÏŒ dataset - Ï‡ÏÎ®ÏƒÎ· Î±Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Ï‰Î½ QC metrics")
            self._calculate_simple_qc_metrics()
            return
        
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î¼Î½Î®Î¼Î·Ï‚ Ï€ÏÎ¹Î½ Ï„Î¿Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ
        memory_info = memory_manager.get_system_memory_info()
        dataset_size_mb = memory_manager.estimate_memory_usage(self.adata)
        
        st.info(f"ğŸ’¾ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ QC metrics Î³Î¹Î± dataset {dataset_size_mb:.1f}MB...")
        
        # Î‘Î½ Ï„Î¿ dataset ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Î¼ÎµÎ³Î¬Î»Î¿, Ï‡ÏÎ®ÏƒÎ· Î²ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î·Ï‚ calculation
        if dataset_size_mb > 300 or memory_info['available_gb'] < 3:
            st.info("âš¡ ÎœÎµÎ³Î¬Î»Î¿ dataset - Ï‡ÏÎ®ÏƒÎ· optimized QC calculation...")
            self.adata = memory_manager.progressive_qc_calculation(self.adata)
            return
        
        try:
            # Î’ÎµÎ²Î±Î¯Ï‰ÏƒÎ· ÏŒÏ„Î¹ Ï„Î¿ X matrix ÎµÎ¯Î½Î±Î¹ numeric
            if hasattr(self.adata.X, 'astype'):
                try:
                    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ numeric Î±Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î®Î´Î·
                    if not np.issubdtype(self.adata.X.dtype, np.number):
                        self.adata.X = self.adata.X.astype(np.float32)  # float32 Î±Î½Ï„Î¯ Î³Î¹Î± float64
                except (ValueError, TypeError):
                    # Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹, Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î¼Îµ pandas
                    import pandas as pd
                    st.info("ğŸ”„ ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÎµ numeric format...")
                    df_temp = pd.DataFrame(self.adata.X, 
                                         index=self.adata.obs_names, 
                                         columns=self.adata.var_names)
                    df_numeric = df_temp.apply(pd.to_numeric, errors='coerce').fillna(0)
                    self.adata.X = df_numeric.values.astype(np.float32)
            
            # Memory-safe Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Î¯
            with st.spinner("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ QC metrics..."):
                
                # Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½ Î±Î½Î¬ ÎºÏÏ„Ï„Î±ÏÎ¿ (memory-safe)
                if hasattr(self.adata.X, 'toarray'):
                    # Sparse matrix - chunked calculation
                    n_genes = np.zeros(self.adata.n_obs)
                    chunk_size = min(1000, self.adata.n_obs)
                    
                    for i in range(0, self.adata.n_obs, chunk_size):
                        end_idx = min(i + chunk_size, self.adata.n_obs)
                        chunk = self.adata.X[i:end_idx, :]
                        n_genes[i:end_idx] = (chunk > 0).sum(axis=1).A1
                    
                    self.adata.obs['n_genes'] = n_genes
                else:
                    # Dense matrix
                    n_genes = (self.adata.X > 0).sum(axis=1)
                    self.adata.obs['n_genes'] = np.array(n_genes).flatten()
                
                # Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ counts Î±Î½Î¬ ÎºÏÏ„Ï„Î±ÏÎ¿ (memory-safe)
                if hasattr(self.adata.X, 'toarray'):
                    # Sparse matrix - chunked calculation
                    total_counts = np.zeros(self.adata.n_obs)
                    
                    for i in range(0, self.adata.n_obs, chunk_size):
                        end_idx = min(i + chunk_size, self.adata.n_obs)
                        chunk = self.adata.X[i:end_idx, :]
                        total_counts[i:end_idx] = chunk.sum(axis=1).A1
                    
                    self.adata.obs['total_counts'] = total_counts
                else:
                    # Dense matrix
                    total_counts = self.adata.X.sum(axis=1)
                    self.adata.obs['total_counts'] = np.array(total_counts).flatten()
                
        except MemoryError:
            st.error("âŒ Memory Error - Ï‡ÏÎ®ÏƒÎ· progressive calculation...")
            self.adata = memory_manager.progressive_qc_calculation(self.adata)
            return
        except Exception as e:
            st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ QC: {str(e)}")
            st.info("ğŸ”„ Î§ÏÎ®ÏƒÎ· ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…...")
            self.adata = memory_manager.progressive_qc_calculation(self.adata)
            return
        
        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î¼Î¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÏÎ½ ÎºÎ±Î¹ ÏÎ¹Î²Î¿ÏƒÏ‰Î¼Î¹ÎºÏÎ½ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½ Î¼Îµ memory protection
        try:
            # ÎœÎ¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÎ¬ Î³Î¿Î½Î¯Î´Î¹Î±
            mito_genes = self.adata.var_names.str.startswith('MT-') | self.adata.var_names.str.startswith('mt-')
            if mito_genes.any():
                if hasattr(self.adata.X, 'toarray'):
                    # Sparse matrix - memory-safe calculation
                    mito_subset = self.adata[:, mito_genes]
                    mito_counts = np.array(mito_subset.X.sum(axis=1)).flatten()
                else:
                    mito_counts = self.adata[:, mito_genes].X.sum(axis=1)
                    mito_counts = np.array(mito_counts).flatten()
                
                total_counts_safe = np.array(self.adata.obs['total_counts'])
                # Î‘Ï€Î¿Ï†Ï…Î³Î® Î´Î¹Î±Î¯ÏÎµÏƒÎ·Ï‚ Î¼Îµ 0
                pct_mt = np.where(total_counts_safe > 0, 
                                 (mito_counts / total_counts_safe) * 100, 0)
                self.adata.obs['pct_counts_mt'] = pct_mt
            else:
                self.adata.obs['pct_counts_mt'] = np.zeros(self.adata.n_obs)
            
            # Î¡Î¹Î²Î¿ÏƒÏ‰Î¼Î¹ÎºÎ¬ Î³Î¿Î½Î¯Î´Î¹Î±
            ribo_genes = self.adata.var_names.str.startswith('RPS') | self.adata.var_names.str.startswith('RPL')
            if ribo_genes.any():
                if hasattr(self.adata.X, 'toarray'):
                    # Sparse matrix - memory-safe calculation
                    ribo_subset = self.adata[:, ribo_genes]
                    ribo_counts = np.array(ribo_subset.X.sum(axis=1)).flatten()
                else:
                    ribo_counts = self.adata[:, ribo_genes].X.sum(axis=1)
                    ribo_counts = np.array(ribo_counts).flatten()
                
                total_counts_safe = np.array(self.adata.obs['total_counts'])
                # Î‘Ï€Î¿Ï†Ï…Î³Î® Î´Î¹Î±Î¯ÏÎµÏƒÎ·Ï‚ Î¼Îµ 0
                pct_rb = np.where(total_counts_safe > 0, 
                                 (ribo_counts / total_counts_safe) * 100, 0)
                self.adata.obs['pct_counts_ribo'] = pct_rb
            else:
                self.adata.obs['pct_counts_ribo'] = np.zeros(self.adata.n_obs)
            
            # Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…Ï„Ï„Î¬ÏÏ‰Î½ Î±Î½Î¬ Î³Î¿Î½Î¯Î´Î¹Î¿ (memory-safe)
            if hasattr(self.adata.X, 'toarray'):
                # Sparse matrix - avoid full conversion
                n_cells = np.array((self.adata.X > 0).sum(axis=0)).flatten()
            else:
                n_cells = (self.adata.X > 0).sum(axis=0)
                n_cells = np.array(n_cells).flatten()
            
            self.adata.var['n_cells'] = n_cells
            
        except MemoryError:
            st.error("âŒ Memory Error ÏƒÏ„Î¿Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ secondary metrics - Ï‡ÏÎ®ÏƒÎ· fallback...")
            # Fallback - Î²Î±ÏƒÎ¹ÎºÎ¬ metrics Î¼ÏŒÎ½Î¿
            if 'n_genes' not in self.adata.obs.columns:
                self.adata.obs['n_genes'] = 1000  # Default value
            if 'total_counts' not in self.adata.obs.columns:
                self.adata.obs['total_counts'] = 5000  # Default value
            self.adata.obs['pct_counts_mt'] = np.zeros(self.adata.n_obs)
            self.adata.obs['pct_counts_ribo'] = np.zeros(self.adata.n_obs)
    
    def _calculate_simple_qc_metrics(self):
        """Î‘Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿Ï‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ QC Î³Î¹Î± Î¼Î·-scRNA-seq datasets"""
        
        st.info("ğŸ”§ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î±Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Ï‰Î½ QC metrics...")
        
        # Î“Î¹Î± Î¼Î¹ÎºÏÎ¬ datasets ÏŒÏ€Ï‰Ï‚ Iris, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿Î½ Î±ÏÎ¹Î¸Î¼ÏŒ features Ï‰Ï‚ "genes"
        self.adata.obs['n_genes'] = self.adata.n_vars  # ÎŒÎ»Î± Ï„Î± features
        
        # Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ "counts" = Î¬Î¸ÏÎ¿Î¹ÏƒÎ¼Î± ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Ï„Î¹Î¼ÏÎ½ Î±Î½Î¬ sample
        if hasattr(self.adata.X, 'toarray'):
            total_counts = np.array(self.adata.X.sum(axis=1)).flatten()
        else:
            total_counts = self.adata.X.sum(axis=1)
        
        self.adata.obs['total_counts'] = total_counts
        
        # Î“Î¹Î± Î¼Î·-scRNA-seq data, Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î¼Î¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÎ¬ Î³Î¿Î½Î¯Î´Î¹Î±
        self.adata.obs['pct_counts_mt'] = np.zeros(self.adata.n_obs)
        self.adata.obs['pct_counts_ribo'] = np.zeros(self.adata.n_obs)
        
        st.success("âœ… Î‘Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± QC metrics Ï…Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎ±Î½!")
        st.info(f"ğŸ“Š n_genes: {self.adata.obs['n_genes'].iloc[0]} (features)")
        st.info(f"ğŸ“Š total_counts range: {total_counts.min():.1f} - {total_counts.max():.1f}")
    
    def _plot_qc_histograms(self):
        """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± histograms Î³Î¹Î± QC metrics Î¼Îµ memory protection"""
        
        st.markdown("##### ğŸ“Š ÎšÎ±Ï„Î±Î½Î¿Î¼Î­Ï‚ QC Metrics")
        
        try:
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï„Î± QC metrics Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½
            required_metrics = ['n_genes', 'total_counts', 'pct_counts_mt', 'pct_counts_ribo']
            missing_metrics = [m for m in required_metrics if m not in self.adata.obs.columns]
            
            if missing_metrics:
                st.warning(f"âš ï¸ Î›ÎµÎ¯Ï€Î¿Ï…Î½ metrics: {', '.join(missing_metrics)} - Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚...")
                self._calculate_qc_metrics()
            
            # Memory-safe plotting Î¼Îµ subsample Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
            plot_data = self.adata.obs
            
            # Î‘Î½ Ï€Î¿Î»Î»Î¬ ÎºÏÏ„Ï„Î±ÏÎ±, Ï‡ÏÎ®ÏƒÎ· subsample Î³Î¹Î± plots
            if len(plot_data) > 10000:
                st.info("ğŸ“Š Subsample Î³Î¹Î± visualization (10K ÎºÏÏ„Ï„Î±ÏÎ±)")
                sample_indices = np.random.choice(len(plot_data), 10000, replace=False)
                plot_data = plot_data.iloc[sample_indices]
            
            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± subplots
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=[
                    'Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î“Î¿Î½Î¹Î´Î¯Ï‰Î½ Î±Î½Î¬ ÎšÏÏ„Ï„Î±ÏÎ¿',
                    'Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Counts Î±Î½Î¬ ÎšÏÏ„Ï„Î±ÏÎ¿', 
                    'Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ ÎœÎ¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÏÎ½ Î“Î¿Î½Î¹Î´Î¯Ï‰Î½',
                    'Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ Î¡Î¹Î²Î¿ÏƒÏ‰Î¼Î¹ÎºÏÎ½ Î“Î¿Î½Î¹Î´Î¯Ï‰Î½'
                ]
            )
            
            # Histogram 1: Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½
            fig.add_trace(
                go.Histogram(x=plot_data['n_genes'], nbinsx=50, name='n_genes'),
                row=1, col=1
            )
            
            # Histogram 2: Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ counts
            fig.add_trace(
                go.Histogram(x=plot_data['total_counts'], nbinsx=50, name='total_counts'),
                row=1, col=2
            )
            
            # Histogram 3: ÎœÎ¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÎ¬
            fig.add_trace(
                go.Histogram(x=plot_data['pct_counts_mt'], nbinsx=50, name='pct_mt'),
                row=2, col=1
            )
            
            # Histogram 4: Î¡Î¹Î²Î¿ÏƒÏ‰Î¼Î¹ÎºÎ¬
            fig.add_trace(
                go.Histogram(x=plot_data['pct_counts_ribo'], nbinsx=50, name='pct_ribo'),
                row=2, col=2
            )
            
            fig.update_layout(height=600, showlegend=False, title_text="Quality Control Metrics")
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· QC: {str(e)}")
            st.info("ğŸ’¡ Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¼Îµ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ dataset Î® ÎºÎ¬Î½Ï„Îµ restart Ï„Î·Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚")
    
    def _plot_qc_scatter(self):
        """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± scatter plots Î³Î¹Î± QC metrics Î¼Îµ memory protection"""
        
        st.markdown("##### ğŸ” Î£Ï…ÏƒÏ‡ÎµÏ„Î¯ÏƒÎµÎ¹Ï‚ QC Metrics")
        
        try:
            # Memory-safe plotting Î¼Îµ subsample Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
            plot_data = self.adata.obs
            
            # Î‘Î½ Ï€Î¿Î»Î»Î¬ ÎºÏÏ„Ï„Î±ÏÎ±, Ï‡ÏÎ®ÏƒÎ· subsample Î³Î¹Î± plots
            if len(plot_data) > 10000:
                st.info("ğŸ“Š Subsample Î³Î¹Î± scatter plots (10K ÎºÏÏ„Ï„Î±ÏÎ±)")
                sample_indices = np.random.choice(len(plot_data), 10000, replace=False)
                plot_data = plot_data.iloc[sample_indices]
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Scatter plot: total_counts vs n_genes
                fig1 = px.scatter(
                    x=plot_data['total_counts'],
                    y=plot_data['n_genes'],
                    title='Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Counts vs Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î“Î¿Î½Î¹Î´Î¯Ï‰Î½',
                    labels={'x': 'Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Counts', 'y': 'Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î“Î¿Î½Î¹Î´Î¯Ï‰Î½'}
                )
                st.plotly_chart(fig1, use_container_width=True)
            
            with col2:
                # Scatter plot: total_counts vs pct_mt
                fig2 = px.scatter(
                    x=plot_data['total_counts'],
                    y=plot_data['pct_counts_mt'],
                    title='Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Counts vs % ÎœÎ¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÏÎ½',
                    labels={'x': 'Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Counts', 'y': '% ÎœÎ¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÏÎ½ Î“Î¿Î½Î¹Î´Î¯Ï‰Î½'}
                )
                st.plotly_chart(fig2, use_container_width=True)
                
        except Exception as e:
            st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î± scatter plots: {str(e)}")
            st.info("ğŸ’¡ Î§ÏÎ®ÏƒÎ· ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ®Ï‚ Î±Ï€Î»Î®Ï‚ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚...")
            
            # Fallback - Î±Ï€Î»Î¬ box plots
            try:
                fig = go.Figure()
                fig.add_trace(go.Box(y=plot_data['n_genes'], name='N Genes'))
                fig.update_layout(title="Î‘Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ QC Plot")
                st.plotly_chart(fig, use_container_width=True)
            except:
                st.warning("âš ï¸ Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Ï…Î½Î±Ï„Î® Î· Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· - Ï€Î¿Î»Ï Î¼ÎµÎ³Î¬Î»Î¿ dataset")
    
    def _display_qc_statistics(self):
        """Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ QC"""
        
        st.markdown("##### ğŸ“ˆ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ QC Metrics")
        
        qc_stats = self.adata.obs[['n_genes', 'total_counts', 'pct_counts_mt', 'pct_counts_ribo']].describe()
        st.dataframe(qc_stats, use_container_width=True)
    
    def _render_preprocessing_section(self):
        """Î¤Î¼Î®Î¼Î± preprocessing ÎºÎ±Î¹ filtering"""
        
        st.markdown("#### ğŸ§¹ Filtering & Preprocessing")
        
        # Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ filtering ÏƒÏ„Î¿ sidebar
        st.sidebar.markdown("### âš™ï¸ Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Filtering")
        
        # Filtering ÎºÏ…Ï„Ï„Î¬ÏÏ‰Î½
        st.sidebar.markdown("#### Filtering ÎšÏ…Ï„Ï„Î¬ÏÏ‰Î½")
        # Smart defaults Î³Î¹Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ÏÏ‚ Ï„ÏÏ€Î¿Ï…Ï‚ datasets
        if self.adata.n_obs < 1000 and self.adata.n_vars < 100:
            st.sidebar.info("ğŸ” ÎœÎ¹ÎºÏÏŒ dataset - Ï‡Î±Î»Î±ÏÎ­Ï‚ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹")
            default_min_genes = 1
        else:
            default_min_genes = 200
            
        min_genes = st.sidebar.number_input(
            "Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½ Î±Î½Î¬ ÎºÏÏ„Ï„Î±ÏÎ¿", 
            min_value=0, max_value=10000, value=default_min_genes, step=50
        )
        max_genes = st.sidebar.number_input(
            "ÎœÎ­Î³Î¹ÏƒÏ„Î¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½ Î±Î½Î¬ ÎºÏÏ„Ï„Î±ÏÎ¿", 
            min_value=1000, max_value=20000, value=5000, step=100
        )
        max_counts = st.sidebar.number_input(
            "ÎœÎ­Î³Î¹ÏƒÏ„Î± ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬ counts Î±Î½Î¬ ÎºÏÏ„Ï„Î±ÏÎ¿", 
            min_value=1000, max_value=100000, value=30000, step=1000
        )
        max_mt = st.sidebar.slider(
            "ÎœÎ­Î³Î¹ÏƒÏ„Î¿ % Î¼Î¹Ï„Î¿Ï‡Î¿Î½Î´ÏÎ¹Î±ÎºÏÎ½ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½", 
            min_value=0.0, max_value=50.0, value=20.0, step=0.5
        )
        
        # Filtering Î³Î¿Î½Î¹Î´Î¯Ï‰Î½
        st.sidebar.markdown("#### Filtering Î“Î¿Î½Î¹Î´Î¯Ï‰Î½")
        min_cells = st.sidebar.number_input(
            "Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…Ï„Ï„Î¬ÏÏ‰Î½ Ï€Î¿Ï… ÎµÎºÏ†ÏÎ¬Î¶Î¿Ï…Î½ Ï„Î¿ Î³Î¿Î½Î¯Î´Î¹Î¿", 
            min_value=1, max_value=100, value=3, step=1
        )
        
        # ÎšÎ¿Ï…Î¼Ï€Î¯ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
        if st.button("ğŸš€ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Preprocessing", type="primary"):
            with st.spinner("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· preprocessing..."):
                self._apply_preprocessing(min_genes, max_genes, max_counts, max_mt, min_cells)
    
    def _apply_preprocessing(self, min_genes, max_genes, max_counts, max_mt, min_cells):
        """Î•Ï†Î±ÏÎ¼Î¿Î³Î® preprocessing steps"""
        
        initial_cells = self.adata.n_obs
        initial_genes = self.adata.n_vars
        
        st.markdown("#### ğŸ“‹ Preprocessing Steps")
        
        # Step 1: Filtering ÎºÏ…Ï„Ï„Î¬ÏÏ‰Î½
        st.write("**Î’Î®Î¼Î± 1: Filtering ÎºÏ…Ï„Ï„Î¬ÏÏ‰Î½**")
        
        # Filter by number of genes
        cell_filter = (
            (self.adata.obs['n_genes'] >= min_genes) &
            (self.adata.obs['n_genes'] <= max_genes) &
            (self.adata.obs['total_counts'] <= max_counts) &
            (self.adata.obs['pct_counts_mt'] <= max_mt)
        )
        
        # CRITICAL CHECK before applying filter
        cells_passing = cell_filter.sum()
        st.write(f"- Cells passing filter: {cells_passing:,}/{self.adata.n_obs:,}")
        
        if cells_passing == 0:
            st.error("âŒ ÎšÎ¡Î™Î£Î™ÎœÎŸ: ÎŒÎ»Î± Ï„Î± ÎºÏÏ„Ï„Î±ÏÎ± Î¸Î± Ï†Î¹Î»Ï„ÏÎ±ÏÎ¹ÏƒÏ„Î¿ÏÎ½!")
            
            # Smart suggestions Î³Î¹Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ÏÏ‚ Ï„ÏÏ€Î¿Ï…Ï‚ datasets
            if self.adata.n_obs < 1000 and self.adata.n_vars < 100:
                st.warning("ğŸ” Î¦Î±Î¯Î½ÎµÏ„Î±Î¹ ÏŒÏ„Î¹ Î±Ï…Ï„ÏŒ Î”Î•Î ÎµÎ¯Î½Î±Î¹ scRNA-seq dataset!")
                st.info("ğŸ’¡ Î“Î¹Î± Î¼Î¹ÎºÏÎ¬ datasets (ÏŒÏ€Ï‰Ï‚ Iris), Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï€Î¿Î»Ï Ï‡Î±Î»Î±ÏÎ­Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚:")
                st.info("   - Min genes: 1-2")
                st.info("   - Max genes: 1000+") 
                st.info("   - Max counts: 100,000+")
                st.info("   - Max MT%: 100%")
            else:
                st.error("Î§Î±Î»Î±ÏÏÏƒÏ„Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Ï†Î¹Î»Ï„ÏÎ±ÏÎ¯ÏƒÎ¼Î±Ï„Î¿Ï‚!")
            
            # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· current ranges Î³Î¹Î± guidance
            st.write("**Î¤ÏÎ­Ï‡Î¿Ï…ÏƒÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±:**")
            st.write(f"- n_genes range: {self.adata.obs['n_genes'].min()} - {self.adata.obs['n_genes'].max()}")
            st.write(f"- total_counts range: {self.adata.obs['total_counts'].min():.0f} - {self.adata.obs['total_counts'].max():.0f}")
            st.write(f"- pct_counts_mt range: {self.adata.obs['pct_counts_mt'].min():.1f}% - {self.adata.obs['pct_counts_mt'].max():.1f}%")
            return
        
        self.adata = self.adata[cell_filter, :]
        st.write(f"- ÎšÏÏ„Ï„Î±ÏÎ± Î¼ÎµÏ„Î¬ Ï„Î¿ filtering: {self.adata.n_obs} (Î±Ï€ÏŒ {initial_cells})")
        
        # Step 2: Filtering Î³Î¿Î½Î¹Î´Î¯Ï‰Î½
        st.write("**Î’Î®Î¼Î± 2: Filtering Î³Î¿Î½Î¹Î´Î¯Ï‰Î½**")
        
        # ÎÎ±Î½Î±Ï‹Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ n_cells Î¼ÎµÏ„Î¬ Ï„Î¿ cell filtering
        try:
            n_cells_per_gene = (self.adata.X > 0).sum(axis=0)
            
            # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ flat array Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
            if hasattr(n_cells_per_gene, 'A1'):  # sparse matrix result
                n_cells_per_gene = n_cells_per_gene.A1
            elif hasattr(n_cells_per_gene, 'flatten'):  # numpy array
                n_cells_per_gene = n_cells_per_gene.flatten()
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ Ï€ÏÎ¹Î½ Ï„Î·Î½ ÎµÎºÏ‡ÏÏÎ·ÏƒÎ·
            if len(n_cells_per_gene) == self.adata.n_vars:
                self.adata.var['n_cells'] = n_cells_per_gene
            else:
                st.warning(f"Mismatch: {len(n_cells_per_gene)} vs {self.adata.n_vars} Î³Î¿Î½Î¯Î´Î¹Î±")
                # Fallback: Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï‡Ï‰ÏÎ¯Ï‚ matrix operations
                self.adata.var['n_cells'] = 1  # Default safe value
        except Exception as e:
            st.warning(f"Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ n_cells: {str(e)}")
            self.adata.var['n_cells'] = 1  # Default safe value
            
        gene_filter = self.adata.var['n_cells'] >= min_cells
        self.adata = self.adata[:, gene_filter]
        st.write(f"- Î“Î¿Î½Î¯Î´Î¹Î± Î¼ÎµÏ„Î¬ Ï„Î¿ filtering: {self.adata.n_vars} (Î±Ï€ÏŒ {initial_genes})")
        
        # Step 3: Normalization
        st.write("**Î’Î®Î¼Î± 3: Normalization**")
        
        # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· raw counts
        self.adata.raw = self.adata
        
        # Normalization ÏƒÎµ 10,000 reads per cell
        sc.pp.normalize_total(self.adata, target_sum=1e4)
        
        # Log transformation
        sc.pp.log1p(self.adata)
        
        st.write("- Normalization ÎºÎ±Î¹ log transformation Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎ±Î½")
        
        # Step 4: Highly variable genes
        st.write("**Î’Î®Î¼Î± 4: Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ highly variable genes**")
        
        try:
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï„Î¿ dataset ÎµÎ¯Î½Î±Î¹ Î±ÏÎºÎµÏ„Î¬ Î¼ÎµÎ³Î¬Î»Î¿ Î³Î¹Î± HVG analysis
            if self.adata.n_vars >= 10 and self.adata.n_obs >= 10:
                sc.pp.highly_variable_genes(self.adata, min_mean=0.0125, max_mean=3, min_disp=0.5)
                n_hvg = self.adata.var['highly_variable'].sum()
                st.write(f"- Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {n_hvg} highly variable genes")
            else:
                # Î“Î¹Î± Î¼Î¹ÎºÏÎ¬ datasets, Î¸ÎµÏ‰ÏÎ¿ÏÎ¼Îµ ÏŒÎ»Î± Ï„Î± Î³Î¿Î½Î¯Î´Î¹Î± Ï‰Ï‚ highly variable
                self.adata.var['highly_variable'] = True
                self.adata.var['dispersions_norm'] = 1.0
                self.adata.var['means'] = self.adata.X.mean(axis=0)
                if hasattr(self.adata.var['means'], 'A1'):
                    self.adata.var['means'] = self.adata.var['means'].A1
                st.write(f"- Dataset Î¼Î¹ÎºÏÏŒ: ÏŒÎ»Î± Ï„Î± {self.adata.n_vars} Î³Î¿Î½Î¯Î´Î¹Î± Î¸ÎµÏ‰ÏÎ¿ÏÎ½Ï„Î±Î¹ highly variable")
        except Exception as e:
            st.warning(f"Î ÏÏŒÎ²Î»Î·Î¼Î± Î¼Îµ HVG analysis: {str(e)}")
            # Fallback: ÏŒÎ»Î± Ï„Î± Î³Î¿Î½Î¯Î´Î¹Î± Ï‰Ï‚ highly variable
            self.adata.var['highly_variable'] = True
            self.adata.var['dispersions_norm'] = 1.0
            st.write(f"- Fallback: ÏŒÎ»Î± Ï„Î± {self.adata.n_vars} Î³Î¿Î½Î¯Î´Î¹Î± Î¸ÎµÏ‰ÏÎ¿ÏÎ½Ï„Î±Î¹ highly variable")
        
        st.success("âœ… Preprocessing Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!")
        
        # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ session state Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· Î±Ï€ÏŒ Î¬Î»Î»ÎµÏ‚ ÏƒÎµÎ»Î¯Î´ÎµÏ‚
        st.session_state['preprocessed_adata'] = self.adata.copy()
        st.session_state['preprocessing_completed'] = True
    
    def _render_results_section(self):
        """Î¤Î¼Î®Î¼Î± Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½"""
        
        st.markdown("#### ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Preprocessing")
        
        if hasattr(st.session_state, 'preprocessed_adata'):
            processed_adata = st.session_state['preprocessed_adata']
            
            # Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Ï€ÏÎ¹Î½ ÎºÎ±Î¹ Î¼ÎµÏ„Î¬
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### Î ÏÎ¹Î½ Ï„Î¿ Preprocessing")
                if self.original_adata is not None:
                    st.metric("ÎšÏÏ„Ï„Î±ÏÎ±", f"{self.original_adata.n_obs:,}")
                    st.metric("Î“Î¿Î½Î¯Î´Î¹Î±", f"{self.original_adata.n_vars:,}")
                else:
                    st.info("ğŸ’¾ Original data Î´ÎµÎ½ Î´Î¹Î±Ï„Î·ÏÎ®Î¸Î·ÎºÎµ Î»ÏŒÎ³Ï‰ Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚")
                    st.metric("ÎšÏÏ„Ï„Î±ÏÎ±", "N/A")
                    st.metric("Î“Î¿Î½Î¯Î´Î¹Î±", "N/A")
                
            with col2:
                st.markdown("##### ÎœÎµÏ„Î¬ Ï„Î¿ Preprocessing")
                st.metric("ÎšÏÏ„Ï„Î±ÏÎ±", f"{processed_adata.n_obs:,}")
                st.metric("Î“Î¿Î½Î¯Î´Î¹Î±", f"{processed_adata.n_vars:,}")
                if 'highly_variable' in processed_adata.var.columns:
                    hvg_count = processed_adata.var['highly_variable'].sum()
                    st.metric("Highly Variable Genes", f"{hvg_count:,}")
            
            # Î”Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± download
            if st.button("ğŸ’¾ Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"):
                self._save_processed_data(processed_adata)
        else:
            st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±. Î•ÎºÏ„ÎµÎ»Î­ÏƒÏ„Îµ Ï€ÏÏÏ„Î± Ï„Î¿ preprocessing.")
    
    def _save_processed_data(self, adata):
        """Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"""
        
        try:
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ session state Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· Î±Ï€ÏŒ Î¬Î»Î»ÎµÏ‚ ÏƒÎµÎ»Î¯Î´ÎµÏ‚
            st.session_state['preprocessed_adata'] = adata.copy()
            st.session_state['preprocessing_completed'] = True
            
            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î¼Îµ Î±ÏƒÏ†Î±Î»Î® Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒ
            import time
            timestamp = int(time.time())
            temp_filename = f"preprocessed_data_{timestamp}.h5ad"
            
            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± temp directory Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
            temp_dir = Path("temp_files")
            temp_dir.mkdir(exist_ok=True)
            
            temp_path = temp_dir / temp_filename
            
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Îµ compression Î³Î¹Î± Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚
            adata.write_h5ad(temp_path, compression='gzip')
            
            # Î”Î¹Î¬Î²Î±ÏƒÎ¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î³Î¹Î± download
            with open(temp_path, 'rb') as f:
                data = f.read()
            
            st.download_button(
                label="ğŸ“¥ ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î± H5AD Î±ÏÏ‡ÎµÎ¯Î¿Ï…",
                data=data,
                file_name="preprocessed_data.h5ad",
                mime="application/octet-stream",
                help="ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î¿ dataset"
            )
            
            # Î‘ÏƒÏ†Î±Î»Î®Ï‚ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…
            try:
                if temp_path.exists():
                    temp_path.unlink()
            except:
                pass  # Î‘Î½ Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹Î±Î³ÏÎ±Ï†ÎµÎ¯, Î´ÎµÎ½ Ï€ÎµÎ¹ÏÎ¬Î¶ÎµÎ¹
                
            st.success("âœ… Î”ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!")
            st.info("ğŸ’¡ Î¤Î± Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· ÏƒÏ„Î¹Ï‚ ÎµÏ€ÏŒÎ¼ÎµÎ½ÎµÏ‚ ÏƒÎµÎ»Î¯Î´ÎµÏ‚")
            
        except Exception as e:
            st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·: {str(e)}")
            # Î¤Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ session state
            try:
                st.session_state['preprocessed_adata'] = adata.copy()
                st.session_state['preprocessing_completed'] = True
                st.info("ğŸ’¾ Î”ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î· Î¼Î½Î®Î¼Î· Ï„Î·Ï‚ ÏƒÏ…Î½ÎµÎ´ÏÎ¯Î±Ï‚")
            except Exception:
                st.error("âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚ ÏƒÏ„Î· Î¼Î½Î®Î¼Î· ÏƒÏ…Î½ÎµÎ´ÏÎ¯Î±Ï‚")
