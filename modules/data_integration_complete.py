"""
ÎŸÎ»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î¿ Module Î³Î¹Î± Ï„Î·Î½ Î•Î½Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î¼Îµ Scanorama

Î‘Ï…Ï„ÏŒ Ï„Î¿ module Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯ÎµÏ‚ Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹ Î³Î¹Î± Ï„Î·Î½
ÎµÎ½Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ scRNA-seq datasets, ÏƒÏ…Î¼Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î±Î½Î¿Î¼Î­Î½Î¿Ï… Ï„Î¿Ï… batch correction
Î¼Îµ Scanorama ÎºÎ±Î¹ Ï„Î·Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Ï„Î·Ï‚ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Ï„Î·Ï‚ integration.


Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±: 2025
"""

import streamlit as st
import pandas as pd
import numpy as np
import scanpy as sc
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import io
import tempfile
import os
import sys
from pathlib import Path

# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· utils directory ÏƒÏ„Î¿ path
sys.path.append(str(Path(__file__).parent.parent / "utils"))

try:
    from memory_utils import memory_monitor, display_memory_info
    from advanced_memory import memory_manager
except ImportError:
    def memory_monitor(func):
        return func
    def display_memory_info():
        pass

# Scanorama import Î¼Îµ error handling
try:
    import scanorama
    SCANORAMA_AVAILABLE = True
except ImportError:
    SCANORAMA_AVAILABLE = False

class DataIntegrationPageComplete:
    """ÎŸÎ»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î· ÎºÎ»Î¬ÏƒÎ· Î³Î¹Î± Ï„Î· ÏƒÎµÎ»Î¯Î´Î± ÎµÎ½Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"""
    
    def __init__(self):
        self.datasets = {}
        self.integrated_data = None
        self.integration_method = "simple_concatenation"
        
    def render(self):
        """ÎšÎµÎ½Ï„ÏÎ¹ÎºÎ® Î¼Î­Î¸Î¿Î´Î¿Ï‚ Î³Î¹Î± Ï„Î·Î½ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î·Ï‚ ÏƒÎµÎ»Î¯Î´Î±Ï‚"""
        
        st.title("ğŸ”— Î•Î½Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
        st.markdown("### Batch correction ÎºÎ±Î¹ ÎµÎ½Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ scRNA-seq datasets")
        
        if not SCANORAMA_AVAILABLE:
            st.warning("âš ï¸ Scanorama Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎµÎ³ÎºÎ±Ï„ÎµÏƒÏ„Î·Î¼Î­Î½Î¿. Î§ÏÎ®ÏƒÎ· ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï….")
        
        # Memory information
        display_memory_info()
        
        # Tabs Î³Î¹Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯ÎµÏ‚
        tab1, tab2, tab3 = st.tabs([
            "ğŸ“ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· & Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹", 
            "ğŸ”„ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Integration",
            "ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±"
        ])
        
        with tab1:
            self.render_setup()
            
        with tab2:
            self.render_execution()
            
        with tab3:
            self.render_results()
    
    def render_setup(self):
        """Î¦ÏŒÏÏ„Ï‰ÏƒÎ· datasets ÎºÎ±Î¹ ÏÏÎ¸Î¼Î¹ÏƒÎ· Ï€Î±ÏÎ±Î¼ÎµÏ„ÏÏÎ½"""
        
        st.header("ğŸ“ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Datasets")
        
        # Î•Ï€Î¹Î»Î¿Î³Î® Î¼ÎµÎ¸ÏŒÎ´Î¿Ï… Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚
        upload_method = st.radio(
            "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î¼Î­Î¸Î¿Î´Î¿ Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚:",
            ["Î§ÏÎ®ÏƒÎ· Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½", "Î‘Î½Î­Î²Î±ÏƒÎ¼Î± Î‘ÏÏ‡ÎµÎ¯Ï‰Î½"],
            horizontal=True
        )
        
        if upload_method == "Î§ÏÎ®ÏƒÎ· Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½":
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÏ„Î¿ session state
            if 'adata' in st.session_state and st.session_state.adata is not None:
                st.info("ğŸ“Š Î’ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ Ï„Î¿ Preprocessing module")
                
                if st.button("Î§ÏÎ®ÏƒÎ· Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"):
                    self.datasets['preprocessed_data'] = st.session_state.adata.copy()
                    st.success("âœ… Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎ±Î½!")
            else:
                st.warning("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
        
        else:
            # Multiple file uploader
            uploaded_files = st.file_uploader(
                "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ H5AD Î±ÏÏ‡ÎµÎ¯Î±:",
                type=['h5ad'],
                accept_multiple_files=True
            )
            
            if uploaded_files:
                for uploaded_file in uploaded_files:
                    dataset_name = uploaded_file.name.replace('.h5ad', '')
                    
                    if dataset_name not in self.datasets:
                        try:
                            with tempfile.NamedTemporaryFile(delete=False, suffix='.h5ad') as tmp_file:
                                tmp_file.write(uploaded_file.getvalue())
                                tmp_path = tmp_file.name
                            
                            with st.spinner(f"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· {dataset_name}..."):
                                adata = sc.read_h5ad(tmp_path)
                                adata = memory_manager.optimize_adata_for_memory(adata)
                                self.datasets[dataset_name] = adata
                            
                            os.unlink(tmp_path)
                            st.success(f"âœ… Dataset '{dataset_name}' Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ!")
                            
                        except Exception as e:
                            st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ {dataset_name}: {str(e)}")
        
        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï†Î¿ÏÏ„Ï‰Î¼Î­Î½Ï‰Î½ datasets
        if self.datasets:
            st.subheader("ğŸ“Š Î¦Î¿ÏÏ„Ï‰Î¼Î­Î½Î± Datasets")
            
            for dataset_name, adata in self.datasets.items():
                with st.expander(f"Dataset: {dataset_name}"):
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("ÎšÏÏ„Ï„Î±ÏÎ±", f"{adata.n_obs:,}")
                    with col2:
                        st.metric("Î“Î¿Î½Î¯Î´Î¹Î±", f"{adata.n_vars:,}")
                    with col3:
                        memory_size = memory_manager.estimate_memory_usage(adata)
                        st.metric("ÎœÎ­Î³ÎµÎ¸Î¿Ï‚", f"{memory_size:.1f} MB")
            
            # Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Integration
            st.subheader("âš™ï¸ Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Integration")
            
            col1, col2 = st.columns(2)
            
            with col1:
                available_methods = ["simple_concatenation"]
                if SCANORAMA_AVAILABLE and len(self.datasets) > 1:
                    available_methods.insert(0, "scanorama")
                
                self.integration_method = st.selectbox(
                    "ÎœÎ­Î¸Î¿Î´Î¿Ï‚ Integration:",
                    available_methods
                )
            
            with col2:
                self.intersection_only = st.checkbox(
                    "Î§ÏÎ®ÏƒÎ· Î¼ÏŒÎ½Î¿ ÎºÎ¿Î¹Î½ÏÎ½ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½",
                    value=True,
                    help="Î”Î¹Î±Ï„Î®ÏÎ·ÏƒÎ· Î¼ÏŒÎ½Î¿ Ï„Ï‰Î½ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½ Ï€Î¿Ï… Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÎµ ÏŒÎ»Î± Ï„Î± datasets"
                )
    
    @memory_monitor
    def render_execution(self):
        """Î•ÎºÏ„Î­Î»ÎµÏƒÎ· integration"""
        
        st.header("ğŸ”„ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Integration")
        
        if not self.datasets:
            st.warning("âš ï¸ Î¦Î¿ÏÏ„ÏÏƒÏ„Îµ Ï€ÏÏÏ„Î± datasets")
            return
        
        if len(self.datasets) < 1:
            st.warning("âš ï¸ Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 1 dataset")
            return
        
        # Î ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·
        st.subheader("ğŸ“‹ Î ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·")
        
        total_cells = sum(adata.n_obs for adata in self.datasets.values())
        common_genes = self.get_common_genes()
        total_genes = len(common_genes) if self.intersection_only and common_genes else max(adata.n_vars for adata in self.datasets.values())
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ ÎšÏÏ„Ï„Î±ÏÎ±", f"{total_cells:,}")
        with col2:
            st.metric("Î“Î¿Î½Î¯Î´Î¹Î±", f"{total_genes:,}")
        with col3:
            estimated_memory = sum(memory_manager.estimate_memory_usage(adata) for adata in self.datasets.values()) * 1.5
            st.metric("Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î· ÎœÎ½Î®Î¼Î·", f"{estimated_memory:.1f} MB")
        
        # ÎšÎ¿Ï…Î¼Ï€Î¯ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
        if st.button("ğŸš€ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Integration", type="primary"):
            try:
                with st.spinner("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· integration..."):
                    self.integrated_data = self.perform_integration()
                
                if self.integrated_data is not None:
                    st.success("âœ… Integration Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!")
                    
                    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ session state
                    st.session_state['integrated_data'] = self.integrated_data
                    
                    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ÎšÏÏ„Ï„Î±ÏÎ±", f"{self.integrated_data.n_obs:,}")
                    with col2:
                        st.metric("Î“Î¿Î½Î¯Î´Î¹Î±", f"{self.integrated_data.n_vars:,}")
                
            except Exception as e:
                st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ integration: {str(e)}")
    
    def get_common_genes(self):
        """Î•ÏÏÎµÏƒÎ· ÎºÎ¿Î¹Î½ÏÎ½ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½"""
        if not self.datasets:
            return []
        
        common_genes = None
        for adata in self.datasets.values():
            if common_genes is None:
                common_genes = set(adata.var_names)
            else:
                common_genes &= set(adata.var_names)
        
        return list(common_genes) if common_genes else []
    
    def perform_integration(self):
        """Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î·Ï‚ integration"""
        
        if len(self.datasets) == 1:
            # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Î­Î½Î± dataset, Î±Ï€Î»Î¬ Ï„Î¿ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ
            dataset_name, adata = next(iter(self.datasets.items()))
            adata_copy = adata.copy()
            adata_copy.obs['dataset'] = dataset_name
            return adata_copy
        
        if self.integration_method == "scanorama" and SCANORAMA_AVAILABLE:
            return self.perform_scanorama_integration()
        else:
            return self.perform_simple_concatenation()
    
    def perform_scanorama_integration(self):
        """Integration Î¼Îµ Scanorama"""
        
        st.info("ğŸ”¬ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Scanorama integration...")
        
        # Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        datasets_list = []
        genes_list = []
        
        for dataset_name, adata in self.datasets.items():
            if hasattr(adata.X, 'toarray'):
                X_dense = adata.X.toarray()
            else:
                X_dense = adata.X
            
            datasets_list.append(X_dense)
            genes_list.append(adata.var_names.tolist())
        
        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Scanorama
        integrated_data, genes = scanorama.integrate(
            datasets_list,
            genes_list,
            knn=20,
            sigma=15.0,
            alpha=0.1,
            batch_size=5000
        )
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± AnnData object
        integrated_X = np.vstack(integrated_data)
        
        # Î£Ï…Î»Î»Î¿Î³Î® obs data
        obs_list = []
        for dataset_name, adata in self.datasets.items():
            obs_subset = adata.obs.copy()
            obs_subset['dataset'] = dataset_name
            obs_list.append(obs_subset)
        
        integrated_obs = pd.concat(obs_list, ignore_index=True)
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± var data
        integrated_var = pd.DataFrame(index=genes)
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± AnnData
        integrated_adata = sc.AnnData(
            X=integrated_X,
            obs=integrated_obs,
            var=integrated_var
        )
        
        return memory_manager.optimize_adata_for_memory(integrated_adata)
    
    def perform_simple_concatenation(self):
        """Î‘Ï€Î»Î® concatenation"""
        
        st.info("ğŸ”— Î•ÎºÏ„Î­Î»ÎµÏƒÎ· simple concatenation...")
        
        # Î•ÏÏÎµÏƒÎ· ÎºÎ¿Î¹Î½ÏÎ½ Î³Î¿Î½Î¹Î´Î¯Ï‰Î½ Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
        if self.intersection_only:
            common_genes = self.get_common_genes()
            if not common_genes and len(self.datasets) > 1:
                st.error("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎºÎ¿Î¹Î½Î¬ Î³Î¿Î½Î¯Î´Î¹Î±")
                return None
        
        # Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± datasets
        processed_datasets = []
        
        for dataset_name, adata in self.datasets.items():
            adata_copy = adata.copy()
            
            # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î³Î¹Î± ÎºÎ¿Î¹Î½Î¬ Î³Î¿Î½Î¯Î´Î¹Î±
            if self.intersection_only and common_genes and len(self.datasets) > 1:
                adata_copy = adata_copy[:, common_genes]
            
            # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· dataset information
            adata_copy.obs['dataset'] = dataset_name
            
            processed_datasets.append(adata_copy)
        
        # Concatenation
        if len(processed_datasets) == 1:
            integrated_adata = processed_datasets[0]
        else:
            integrated_adata = sc.concat(processed_datasets, axis=0, join='outer')
        
        return memory_manager.optimize_adata_for_memory(integrated_adata)
    
    def render_results(self):
        """Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½"""
        
        st.header("ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Integration")
        
        if self.integrated_data is None:
            if 'integrated_data' in st.session_state:
                self.integrated_data = st.session_state['integrated_data']
            else:
                st.warning("âš ï¸ Î•ÎºÏ„ÎµÎ»Î­ÏƒÏ„Îµ Ï€ÏÏÏ„Î± integration")
                return
        
        # Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ­Ï‚
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ ÎšÏÏ„Ï„Î±ÏÎ±", f"{self.integrated_data.n_obs:,}")
        with col2:
            st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Î“Î¿Î½Î¯Î´Î¹Î±", f"{self.integrated_data.n_vars:,}")
        with col3:
            if 'dataset' in self.integrated_data.obs.columns:
                n_datasets = self.integrated_data.obs['dataset'].nunique()
                st.metric("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Datasets", n_datasets)
        
        # Dataset distribution
        if 'dataset' in self.integrated_data.obs.columns:
            st.subheader("ğŸ“Š ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎšÏ…Ï„Ï„Î¬ÏÏ‰Î½ Î±Î½Î¬ Dataset")
            
            dataset_counts = self.integrated_data.obs['dataset'].value_counts()
            
            fig = px.bar(
                x=dataset_counts.index,
                y=dataset_counts.values,
                labels={'x': 'Dataset', 'y': 'Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎšÏ…Ï„Ï„Î¬ÏÏ‰Î½'},
                title="ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎšÏ…Ï„Ï„Î¬ÏÏ‰Î½ Î±Î½Î¬ Dataset"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Visualization
        st.subheader("ğŸ“ˆ ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·")
        
        viz_method = st.selectbox(
            "ÎœÎ­Î¸Î¿Î´Î¿Ï‚ Visualization:",
            ["PCA", "UMAP", "t-SNE"]
        )
        
        if st.button(f"Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± {viz_method} Plot"):
            try:
                with st.spinner(f"Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ {viz_method}..."):
                    
                    if viz_method == "PCA":
                        sc.tl.pca(self.integrated_data)
                        basis = 'pca'
                    elif viz_method == "UMAP":
                        sc.tl.pca(self.integrated_data)
                        sc.pp.neighbors(self.integrated_data)
                        sc.tl.umap(self.integrated_data)
                        basis = 'umap'
                    else:  # t-SNE
                        sc.tl.pca(self.integrated_data)
                        sc.tl.tsne(self.integrated_data)
                        basis = 'tsne'
                    
                    # Plot
                    fig, ax = plt.subplots(figsize=(10, 8))
                    
                    if 'dataset' in self.integrated_data.obs.columns:
                        sc.pl.embedding(
                            self.integrated_data, 
                            basis=basis, 
                            color='dataset',
                            ax=ax,
                            show=False,
                            frameon=False
                        )
                        ax.set_title(f'{viz_method} - Colored by Dataset')
                    
                    st.pyplot(fig)
                    
            except Exception as e:
                st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·: {str(e)}")
        
        # Export
        st.subheader("ğŸ’¾ Export Data")
        
        export_format = st.selectbox("ÎœÎ¿ÏÏ†Î® Export:", ["H5AD", "CSV"])
        
        if st.button("ğŸ“¥ Download Data"):
            try:
                if export_format == "H5AD":
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.h5ad') as tmp_file:
                        self.integrated_data.write_h5ad(tmp_file.name)
                        
                        with open(tmp_file.name, 'rb') as f:
                            st.download_button(
                                label="ğŸ’¾ Download H5AD",
                                data=f.read(),
                                file_name="integrated_data.h5ad",
                                mime="application/octet-stream"
                            )
                        
                        os.unlink(tmp_file.name)
                
                else:  # CSV
                    if hasattr(self.integrated_data.X, 'toarray'):
                        X_dense = self.integrated_data.X.toarray()
                    else:
                        X_dense = self.integrated_data.X
                    
                    df = pd.DataFrame(
                        X_dense,
                        index=self.integrated_data.obs_names,
                        columns=self.integrated_data.var_names
                    )
                    
                    csv_buffer = io.StringIO()
                    df.to_csv(csv_buffer)
                    
                    st.download_button(
                        label="ğŸ’¾ Download CSV",
                        data=csv_buffer.getvalue(),
                        file_name="integrated_data.csv",
                        mime="text/csv"
                    )
                
            except Exception as e:
                st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿ export: {str(e)}")
