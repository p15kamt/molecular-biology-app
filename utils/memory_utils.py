"""
Utility functions Î³Î¹Î± Memory Management

Î‘Ï…Ï„ÏŒ Ï„Î¿ module Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Î²Î¿Î·Î¸Î·Ï„Î¹ÎºÎ­Ï‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î· Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚
ÎºÎ±Î¹ Ï„Î·Î½ optimization Ï„Î·Ï‚ ÎµÏ€Î¯Î´Î¿ÏƒÎ·Ï‚ Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± datasets.


Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±: 2025
"""

import psutil
import gc
import streamlit as st
import numpy as np
import pandas as pd
from functools import wraps

def get_memory_usage():
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î·Î½ Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎ± Ï‡ÏÎ®ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ ÏƒÎµ MB"""
    process = psutil.Process()
    memory_info = process.memory_info()
    return memory_info.rss / 1024 / 1024  # Convert to MB

def get_available_memory():
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î· Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î· Î¼Î½Î®Î¼Î· ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ ÏƒÎµ MB"""
    memory = psutil.virtual_memory()
    return memory.available / 1024 / 1024  # Convert to MB

def memory_monitor(func):
    """Decorator Î³Î¹Î± monitoring Ï„Î·Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚ Î¼Î½Î®Î¼Î·Ï‚"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        # ÎœÎ½Î®Î¼Î· Ï€ÏÎ¹Î½ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·
        memory_before = get_memory_usage()
        
        try:
            result = func(*args, **kwargs)
            
            # ÎœÎ½Î®Î¼Î· Î¼ÎµÏ„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·
            memory_after = get_memory_usage()
            memory_diff = memory_after - memory_before
            
            if memory_diff > 100:  # Î‘Î½ Î· Î±ÏÎ¾Î·ÏƒÎ· > 100MB
                st.info(f"ğŸ’¾ Memory usage: +{memory_diff:.1f} MB")
            
            return result
            
        except MemoryError:
            st.error("âŒ Î‘Î½ÎµÏ€Î±ÏÎºÎ®Ï‚ Î¼Î½Î®Î¼Î·! Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¼Îµ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ dataset Î® subsample.")
            gc.collect()  # Force garbage collection
            raise
            
        finally:
            # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¼Î½Î®Î¼Î·Ï‚ Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
            if get_memory_usage() > 2000:  # Î‘Î½ > 2GB
                gc.collect()
    
    return wrapper

@st.cache_data(show_spinner=False)
def cached_data_load(file_path, file_type):
    """Cache-enabled data loading Î³Î¹Î± Î±Ï€Î¿Ï†Ï…Î³Î® ÎµÏ€Î±Î½Î±Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚"""
    import scanpy as sc
    
    if file_type == 'h5ad':
        return sc.read_h5ad(file_path)
    elif file_type in ['csv', 'tsv']:
        separator = ',' if file_type == 'csv' else '\t'
        return pd.read_csv(file_path, sep=separator, index_col=0)
    elif file_type in ['xlsx', 'xls']:
        return pd.read_excel(file_path, index_col=0)

def optimize_adata_memory(adata):
    """Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± AnnData object"""
    
    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ sparse format Î±Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î®Î´Î·
    if not hasattr(adata.X, 'toarray'):
        from scipy.sparse import csr_matrix
        adata.X = csr_matrix(adata.X)
    
    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¬Ï‡ÏÎ·ÏƒÏ„Ï‰Î½ metadata
    if 'raw' in adata.__dict__ and adata.raw is not None:
        # Î”Î¹Î±Ï„Î®ÏÎ·ÏƒÎ· Î¼ÏŒÎ½Î¿ Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
        if len(adata.raw.var_names) == len(adata.var_names):
            adata.raw = None
    
    # Memory optimization Î³Î¹Î± obs/var DataFrames
    for df_name in ['obs', 'var']:
        df = getattr(adata, df_name)
        
        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® object columns ÏƒÎµ category ÏŒÏ€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î´Ï…Î½Î±Ï„ÏŒ
        for col in df.columns:
            if df[col].dtype == 'object':
                unique_ratio = df[col].nunique() / len(df[col])
                if unique_ratio < 0.5:  # Î‘Î½ <50% unique values
                    df[col] = df[col].astype('category')
    
    return adata

def estimate_memory_requirements(n_obs, n_vars, data_type='float32'):
    """Î•ÎºÏ„Î¯Î¼Î·ÏƒÎ· Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÏ‰Î½ Î¼Î½Î®Î¼Î·Ï‚ Î³Î¹Î± dataset"""
    
    if data_type == 'float32':
        bytes_per_element = 4
    elif data_type == 'float64':
        bytes_per_element = 8
    else:
        bytes_per_element = 4  # Default
    
    # Î’Î±ÏƒÎ¹ÎºÎ® ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· Î³Î¹Î± dense matrix
    dense_memory_mb = (n_obs * n_vars * bytes_per_element) / (1024 * 1024)
    
    # Î•ÎºÏ„Î¯Î¼Î·ÏƒÎ· Î³Î¹Î± sparse matrix (Ï…Ï€Î¿Î¸Î­Ï„Î¿Î½Ï„Î±Ï‚ 10% sparsity)
    sparse_memory_mb = dense_memory_mb * 0.1
    
    return {
        'dense_mb': dense_memory_mb,
        'sparse_mb': sparse_memory_mb,
        'recommended_format': 'sparse' if dense_memory_mb > 1000 else 'dense'
    }

def display_memory_info():
    """Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½ Î¼Î½Î®Î¼Î·Ï‚ ÏƒÏ„Î¿ Streamlit"""
    
    current_usage = get_memory_usage()
    available_memory = get_available_memory()
    total_memory = psutil.virtual_memory().total / 1024 / 1024
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "Î§ÏÎ®ÏƒÎ· ÎœÎ½Î®Î¼Î·Ï‚", 
            f"{current_usage:.0f} MB",
            help="Î¤ÏÎ­Ï‡Î¿Ï…ÏƒÎ± Ï‡ÏÎ®ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚ Î±Ï€ÏŒ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®"
        )
    
    with col2:
        st.metric(
            "Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î· ÎœÎ½Î®Î¼Î·", 
            f"{available_memory:.0f} MB",
            help="Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î· Î¼Î½Î®Î¼Î· ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚"
        )
    
    with col3:
        usage_percent = (current_usage / total_memory) * 100
        st.metric(
            "% Î§ÏÎ®ÏƒÎ·", 
            f"{usage_percent:.1f}%",
            help="Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ Ï‡ÏÎ®ÏƒÎ·Ï‚ Ï„Î·Ï‚ ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ®Ï‚ Î¼Î½Î®Î¼Î·Ï‚"
        )
    
    # Warning Î±Î½ Î· Î¼Î½Î®Î¼Î· ÎµÎ¯Î½Î±Î¹ Ï‡Î±Î¼Î·Î»Î®
    if available_memory < 500:  # <500MB available
        st.warning("âš ï¸ Î§Î±Î¼Î·Î»Î® Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î· Î¼Î½Î®Î¼Î·! Î£Ï…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹ subsample Î® restart Ï„Î·Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚.")
    
    return {
        'current_mb': current_usage,
        'available_mb': available_memory,
        'usage_percent': usage_percent
    }

def suggest_optimization(adata):
    """Î ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î¿ dataset"""
    
    suggestions = []
    
    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚
    if adata.n_obs > 50000:
        suggestions.append("ğŸ¯ Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ subsample Î³Î¹Î± Î³ÏÎ·Î³Î¿ÏÏŒÏ„ÎµÏÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·")
    
    if adata.n_vars > 20000:
        suggestions.append("ğŸ§¬ Î•Ï†Î±ÏÎ¼ÏŒÏƒÏ„Îµ feature selection Î³Î¹Î± Î¼ÎµÎ¯Ï‰ÏƒÎ· Î³Î¿Î½Î¹Î´Î¯Ï‰Î½")
    
    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ sparsity
    if hasattr(adata.X, 'toarray'):
        sparsity = 1 - (adata.X.nnz / (adata.n_obs * adata.n_vars))
        if sparsity < 0.5:
            suggestions.append("ğŸ’¾ Dataset Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±ÏÎºÎµÏ„Î¬ sparse - ÎµÎ»Î­Î³Î¾Ï„Îµ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±")
    
    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î¼Î½Î®Î¼Î·Ï‚
    memory_est = estimate_memory_requirements(adata.n_obs, adata.n_vars)
    if memory_est['dense_mb'] > 1000:
        suggestions.append("ğŸ—œï¸ Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ sparse format Î³Î¹Î± ÎµÎ¾Î¿Î¹ÎºÎ¿Î½ÏŒÎ¼Î·ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚")
    
    return suggestions

def cleanup_memory():
    """ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¼Î½Î®Î¼Î·Ï‚ ÎºÎ±Î¹ garbage collection"""
    gc.collect()
    
    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Streamlit cache Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
    if get_memory_usage() > 1500:  # Î‘Î½ > 1.5GB
        st.cache_data.clear()
        st.info("ğŸ§¹ Î•ÎºÎºÎ±Î¸Î¬ÏÎ¹ÏƒÎ· cache Î³Î¹Î± ÎµÎ¾Î¿Î¹ÎºÎ¿Î½ÏŒÎ¼Î·ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚")
